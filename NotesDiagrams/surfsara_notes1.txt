surfsara_findings:m/ $

## submitting to the queue is done using 'qsub'

## using the 'interactive mode' gives you output when the job starts and when it ends (see below). it may give you more information if the script is more complex, for example, if it sprouts other processes, but with my simple script it only gave me start and end.

jheinerm:~/ $ qsub -I test.sh

qsub: waiting for job 8324210.batch1.lisa.surfsara.nl to start

qsub: job 8324210.batch1.lisa.surfsara.nl ready
                                                                                                                                       [0:24:59]
qsub: job 8324210.batch1.lisa.surfsara.nl completed


## qstat gave this output initially:

batch1.lisa.surfsara.nl:
                                                                                                                                                                  Req'd    Req'd       Elap
Job ID                  Username    Queue    Jobname          SessID  NDS   TSK                                                                                   Memory   Time    S   Time
----------------------- ----------- -------- ---------------- ------ ----- -----                                                                                - ------ --------- - ---------
8324010.batch1.lisa.su  jheinerm    express  test.sh             --      1                                                                                      1    --   00:01:00 R  00:00:00
   r41n2/0


## but then it stopped giving output at all. dont know why this is the case, I will log out and back in again later and see if it happens again.

## the system is really slow at the moment because:

jheinerm:~/ $ showq -u jheinerm    
                                                                                                            [0:34:03]
ACTIVE JOBS--------------------
JOBNAME            USERNAME      STATE  PROC   REMAINING            STARTTIME

8324212            jheinerm    Running    16    00:01:00  Thu Sep 18 00:33:35

     1 Active Job     8756 of 8824 Processors Active (99.23%)
                       570 of  575 Nodes Active      (99.13%)

IDLE JOBS----------------------
JOBNAME            USERNAME      STATE  PROC     WCLIMIT            QUEUETIME


0 Idle Jobs

BLOCKED JOBS----------------
JOBNAME            USERNAME      STATE  PROC     WCLIMIT            QUEUETIME


Total Jobs: 1   Active Jobs: 1   Idle Jobs: 0   Blocked Jobs: 0

## the output files are saved in the directory where the script is by default. i dont yet know if this can be edited.

## there are two output files given in the following format:

-rw------- 1 jheinerm jheinerm    0 Sep 18 00:49 test2.sh.e8324213
-rw------- 1 jheinerm jheinerm 2916 Sep 18 00:11 test2.sh.o8324108

## opening the file with 'o' in the name, we see the  console output (the script asks it to show the file contents):

start
/home/jheinerm
total 2.1M
drwx------ 11 jheinerm jheinerm 4.0K Sep 18 00:17 .
drwxr-xr-x  3 root     root        0 Sep 18 00:17 ..
-rw-------  1 jheinerm jheinerm 2.7K Sep 11 00:38 .bash_history
-rw-r--r--  1 jheinerm jheinerm  567 Sep  8 15:16 .bash_profile
-rw-r--r--  1 jheinerm jheinerm  161 Sep 11 00:08 .bashrc
drwx------  9 jheinerm jheinerm  133 Sep 11 00:48 HyperNEAT
drwx------  3 jheinerm jheinerm   96 Sep 11 00:12 hyperneat-originalSources-NOT-COMPILED
drwx------  5 jheinerm jheinerm   40 Sep 11 00:44 libode
drwx------ 14 jheinerm jheinerm 4.0K Sep 11 00:40 ode-0.13
-rw-------  1 jheinerm jheinerm 2.0M Feb  4  2014 ode-0.13.tar.bz2
drwxr-xr-x 11 jheinerm jheinerm 4.0K Sep 11 00:05 .oh-my-zsh
-rw-------  1 jheinerm jheinerm  200 Sep 11 00:01 .profile
drwx------  4 jheinerm jheinerm   45 Sep 17 23:45 softbotEvolution
drwxr-xr-x  2 jheinerm jheinerm   19 Sep  8 15:16 .subversion
drwx------  2 jheinerm jheinerm  129 Sep 18 00:12 testlysa
-rw-------  1 jheinerm jheinerm    6 Sep 18 00:17 testVoxCad14.txt

## the files with 'e' in the name are empty, presumably because they are error logs and we had no errors.

## occasionally i get this error and i haven't been able to figure out why:

jheinerm:testlysa/ $ qstat -n -u jheinerm                                                                                                             [0:16:59]
pbs_iff: cannot connect to batch:15001 - timeout, errno=99 (Cannot assign requested address) $
No Permission.
qstat: cannot connect to server batch (errno=15007) Unauthorized Request

## there are a few different types of nodes in the network with different processor speeds, scratch space, memory, etc. we can specify in qsub which type of node we want:

jheinerm:~/ $ qsub job -lnodes=1:cores16:ppn=1 -lwalltime=00:00:10

## we are able to qsub multiple processes from the same script using #TODO

jheinerm:~/ $ qsub -t 1-100 myjob

## if the script fails to run for whatever reason, it will be resubmitted unless you put -rn in qsub

## It should be noted that only one 'express' job is allowed per user, meaning that it is possible (since the network is currently so loaded and might be this loaded all the time) that it would be faster if we submitted the processes serially. currently the network even took a few seconds for one of my 'express' jobs (the script is so short it should be done in an instant, the delay is not because of my script).

## we can delete jobs using qdel but we can also batch delete using these:

    remove all jobs: qdel 34445[]
    remove some jobs: qdel 34445[] -t 4-30

## i need to read the documentation for 'stopos' as it might be useful for us since we could manage many jobs using stopos

"We developed software ('stopos') to make in possible that you submit many copies of the same jobscript (see above), while taking care that each task in the jobs does exactly what it is supposed to do. Find here a comprehensive description of the stopos software."

## we should request specific nodes based on the type of operation we are running (e.g. if the simulations are memory intensive):

data-intensive: e.g. finite-difference model => nodes with
QPI, 8 cores (so more bandwidth per core)
compute-intensive: e.g. matrix operations => nodes with 12
cores, bandwidth is less important.
memory-intensive: nodes with 24GB of memory

NB: This is old information, I need to find current info about available node types #TODO

CURRENT:

    12-core nodes: 220 Gbyte/node
    16-core nodes: 750 Gbyte/node

Home file system of lisa is shared and very slow. There is something in place to deal with this (scratch space), but I need to read up on it #TODO









surf_sara:m $ PYTHON

## to check which version of python is available use:

module avail python

## to load a specific version (skip the version number if default is ok):

module load python/3.1.2